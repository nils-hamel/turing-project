## inv-hsv-osi-ce training and validation

This study focuses on the analysis of the training and validation performances of the
[inv-hsv-osi-ce](https://github.com/nils-hamel/turing-project/tree/master/src/turing-auto/auto-image/image-inv-hsv-osi-ce)
auto-encoder according to the considered data-set and the size of its hidden layer.

For each considered data-set, the unique hidden layer size is modulated with the
values : 64, 128, 256, 512, 1024 and 2048. The considered data-sets are composed
with 64 by 64 pixels greyscale images. The input and output layers are then each
composed of 4096 neurons.

Each data-set is split in two parts : the training set and the validation parts.
Usually, eighty percent of the data-set is used as training data. The training
is always conducted over 256 epochs and considering a batch size of 128. At each
epoch, the training and validation losses are exported.

## Training and validation performances

The following sub-sections give an analysis of the training and validation
performances of the auto-encoder according to its hidden layer size each for a
specific data-set.

### Dataset : 64x64x3-geneva-2009

This sub-section presents the training results of the network on the
[64x64x3-geneva-2009](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2009.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-2009-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2009.md">64x64x3-geneva-2009</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-2009-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2009.md">64x64x3-geneva-2009</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-2009-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2009.md">64x64x3-geneva-2009</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-geneva-2011

This sub-section presents the training results of the network on the
[64x64x3-geneva-2011](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2011.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-2011-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2011.md">64x64x3-geneva-2011</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-2011-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2011.md">64x64x3-geneva-2011</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-2011-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2011.md">64x64x3-geneva-2011</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-geneva-2016

This sub-section presents the training results of the network on the
[64x64x3-geneva-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2016.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2016.md">64x64x3-geneva-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2016.md">64x64x3-geneva-2016</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2016.md">64x64x3-geneva-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-geneva-oblique-2013

This sub-section presents the training results of the network on the
[64x64x3-geneva-oblique-2013](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-oblique-2013.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-oblique-2013-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-oblique-2013.md">64x64x3-geneva-oblique-2013</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-oblique-2013-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-oblique-2013.md">64x64x3-geneva-oblique-2013</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-geneva-oblique-2013-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-oblique-2013.md">64x64x3-geneva-oblique-2013</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-paris-louvre-2017

This sub-section presents the training results of the network on the
[64x64x3-paris-louvre-2017](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-paris-louvre-2017.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-paris-louvre-2017-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-paris-louvre-2017.md">64x64x3-paris-louvre-2017</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-paris-louvre-2017-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-paris-louvre-2017.md">64x64x3-paris-louvre-2017</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-paris-louvre-2017-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-paris-louvre-2017.md">64x64x3-paris-louvre-2017</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-2004

This sub-section presents the training results of the network on the
[64x64x3-venezia-2004](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2004.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-2004-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2004.md">64x64x3-venezia-2004</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-2004-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2004.md">64x64x3-venezia-2004</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-2004-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2004.md">64x64x3-venezia-2004</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-2010

This sub-section presents the training results of the network on the
[64x64x3-venezia-2010](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2010.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-2010-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2010.md">64x64x3-venezia-2010</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-2010-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2010.md">64x64x3-venezia-2010</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-2010-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2010.md">64x64x3-venezia-2010</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-2014

This sub-section presents the training results of the network on the
[64x64x3-venezia-2014](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2014.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-2014-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2014.md">64x64x3-venezia-2014</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-2014-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2014.md">64x64x3-venezia-2014</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-2014-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2014.md">64x64x3-venezia-2014</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-campanile-2016

This sub-section presents the training results of the network on the
[64x64x3-venezia-campanile-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-campanile-2016.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-campanile-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-campanile-2016.md">64x64x3-venezia-campanile-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-campanile-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-campanile-2016.md">64x64x3-venezia-campanile-2016</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-campanile-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-campanile-2016.md">64x64x3-venezia-campanile-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-palazzo-ducale-2016

This sub-section presents the training results of the network on the
[64x64x3-venezia-palazzo-ducale-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-palazzo-ducale-2016.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-palazzo-ducale-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-palazzo-ducale-2016.md">64x64x3-venezia-palazzo-ducale-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-palazzo-ducale-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-palazzo-ducale-2016.md">64x64x3-venezia-palazzo-ducale-2016</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-palazzo-ducale-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-palazzo-ducale-2016.md">64x64x3-venezia-palazzo-ducale-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-piazza-2016

This sub-section presents the training results of the network on the
[64x64x3-venezia-piazza-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-piazza-2016.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-piazza-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-piazza-2016.md">64x64x3-venezia-piazza-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-piazza-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-piazza-2016.md">64x64x3-venezia-piazza-2016</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-piazza-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-piazza-2016.md">64x64x3-venezia-piazza-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-san-giacometto-2016

This sub-section presents the training results of the network on the
[64x64x3-venezia-san-giacometto-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-giacometto-2016.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-san-giacometto-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-giacometto-2016.md">64x64x3-venezia-san-giacometto-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-san-giacometto-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-giacometto-2016.md">64x64x3-venezia-san-giacometto-2016</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-san-giacometto-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-giacometto-2016.md">64x64x3-venezia-san-giacometto-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-san-marco-2016

This sub-section presents the training results of the network on the
[64x64x3-venezia-san-marco-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-marco-2016.md) data-set and according to the
size of its unique hidden layer. The following plot shows
the evolution of the training and validation losses according to
the training epochs and hidden layer size. The red curves give the evolution of the training
losses while the orange ones show the evolution of the validation losses.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-san-marco-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-marco-2016.md">64x64x3-venezia-san-marco-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-san-marco-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-marco-2016.md">64x64x3-venezia-san-marco-2016</a> data-set</i>
</p>

The following plot also shows examples of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/f343816a10b17cc9/64x64x3-venezia-san-marco-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-marco-2016.md">64x64x3-venezia-san-marco-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

Nils Hamel, 2018-01-16 <br />
Copyright (c) 2018 DHLAB, EPFL
