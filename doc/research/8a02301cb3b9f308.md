### Dataset : 64x64x3-geneva-2009

This sub-section present the training result of the network on the
[64x64x3-geneva-2009](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2009.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-2009-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2009.md">64x64x3-geneva-2009</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-2009-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2009.md">64x64x3-geneva-2009</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-2009-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2009.md">64x64x3-geneva-2009</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-geneva-2011

This sub-section present the training result of the network on the
[64x64x3-geneva-2011](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2011.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-2011-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2011.md">64x64x3-geneva-2011</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-2011-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2011.md">64x64x3-geneva-2011</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-2011-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2011.md">64x64x3-geneva-2011</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-geneva-2016

This sub-section present the training result of the network on the
[64x64x3-geneva-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2016.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2016.md">64x64x3-geneva-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2016.md">64x64x3-geneva-2016</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-2016.md">64x64x3-geneva-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-geneva-oblique-2013

This sub-section present the training result of the network on the
[64x64x3-geneva-oblique-2013](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-oblique-2013.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-oblique-2013-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-oblique-2013.md">64x64x3-geneva-oblique-2013</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-oblique-2013-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-oblique-2013.md">64x64x3-geneva-oblique-2013</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-geneva-oblique-2013-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-geneva-oblique-2013.md">64x64x3-geneva-oblique-2013</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-paris-louvre-2017

This sub-section present the training result of the network on the
[64x64x3-paris-louvre-2017](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-paris-louvre-2017.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-paris-louvre-2017-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-paris-louvre-2017.md">64x64x3-paris-louvre-2017</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-paris-louvre-2017-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-paris-louvre-2017.md">64x64x3-paris-louvre-2017</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-paris-louvre-2017-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-paris-louvre-2017.md">64x64x3-paris-louvre-2017</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-2004

This sub-section present the training result of the network on the
[64x64x3-venezia-2004](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2004.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-2004-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2004.md">64x64x3-venezia-2004</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-2004-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2004.md">64x64x3-venezia-2004</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-2004-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2004.md">64x64x3-venezia-2004</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-2010

This sub-section present the training result of the network on the
[64x64x3-venezia-2010](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2010.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-2010-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2010.md">64x64x3-venezia-2010</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-2010-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2010.md">64x64x3-venezia-2010</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-2010-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2010.md">64x64x3-venezia-2010</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-2014

This sub-section present the training result of the network on the
[64x64x3-venezia-2014](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2014.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-2014-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2014.md">64x64x3-venezia-2014</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-2014-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2014.md">64x64x3-venezia-2014</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-2014-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-2014.md">64x64x3-venezia-2014</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-campanile-2016

This sub-section present the training result of the network on the
[64x64x3-venezia-campanile-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-campanile-2016.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-campanile-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-campanile-2016.md">64x64x3-venezia-campanile-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-campanile-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-campanile-2016.md">64x64x3-venezia-campanile-2016</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-campanile-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-campanile-2016.md">64x64x3-venezia-campanile-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-palazzo-ducale-2016

This sub-section present the training result of the network on the
[64x64x3-venezia-palazzo-ducale-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-palazzo-ducale-2016.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-palazzo-ducale-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-palazzo-ducale-2016.md">64x64x3-venezia-palazzo-ducale-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-palazzo-ducale-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-palazzo-ducale-2016.md">64x64x3-venezia-palazzo-ducale-2016</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-palazzo-ducale-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-palazzo-ducale-2016.md">64x64x3-venezia-palazzo-ducale-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-piazza-2016

This sub-section present the training result of the network on the
[64x64x3-venezia-piazza-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-piazza-2016.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-piazza-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-piazza-2016.md">64x64x3-venezia-piazza-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-piazza-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-piazza-2016.md">64x64x3-venezia-piazza-2016</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-piazza-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-piazza-2016.md">64x64x3-venezia-piazza-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-san-giacometto-2016

This sub-section present the training result of the network on the
[64x64x3-venezia-san-giacometto-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-giacometto-2016.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-san-giacometto-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-giacometto-2016.md">64x64x3-venezia-san-giacometto-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-san-giacometto-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-giacometto-2016.md">64x64x3-venezia-san-giacometto-2016</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-san-giacometto-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-giacometto-2016.md">64x64x3-venezia-san-giacometto-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

### Dataset : 64x64x3-venezia-san-marco-2016

This sub-section present the training result of the network on the
[64x64x3-venezia-san-marco-2016](https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-marco-2016.md) data-set and according to the
size of the network hidden layer. The following plots show
the evolution of the training and validation loss according to
the training epochs. The red curves give the evolution of the training
loss while the orange one shows the evolution of the validation loss.
The title of each sub-plot gives the amount of neurons that are used
in the hidden layer.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-san-marco-2016-loss.jpg?raw=true" width="640">
<br />
<i>Training (red) and validation (orange) losses according to training epochs for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-marco-2016.md">64x64x3-venezia-san-marco-2016</a> data-set</i>
</p>

The following plot shows examples of auto-encoded images using the
trained network. For each trained network, 24 images of the training
set are auto-encoded. In each group of 24 images, each example is presented
using the original image and its auto-encoded counterpart on the right.
The successive images groups are related to the size of the network
hidden layer starting from 64 to 2048.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-san-marco-2016-train.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the training set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-marco-2016.md">64x64x3-venezia-san-marco-2016</a> data-set</i>
</p>

The following plot also shows example of auto-encoded images selected
in the validation set. Again, for each network, 24 images are considered
showing both their original state and their auto-encoded counterpart.

<p align="center">
<img src="https://github.com/nils-hamel/turing-project/blob/master/doc/research/8a02301cb3b9f308/64x64x3-venezia-san-marco-2016-valid.jpg?raw=true" width="600">
<br />
<i>Auto-encoding on the validation set for the <a href="https://github.com/nils-hamel/turing-project/blob/master/doc/dataset/64x64x3-venezia-san-marco-2016.md">64x64x3-venezia-san-marco-2016</a> data-set</i>
</p>

The last two plots have the same form. The first one showing results
on the training set while the second shows results on the validation
set.

